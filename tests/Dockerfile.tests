# Dockerfile
FROM bitnami/spark:3.3.4

USER root

# Spark images (like bitnami/spark) often come with Python and pip pre-installed.
# You might not need to explicitly install them.
# If Python/pip are missing or an older version, uncomment the following lines:
# RUN apt-get update && apt-get install -y python3 python3-pip && \
#     ln -s /usr/bin/python3 /usr/bin/python

# Install Python dependencies required for your tests and ETL process
RUN pip install --no-cache-dir pyspark==3.3.4 pytest==8.4.0

# Set the working directory inside the container.
# This is where your host's current directory will be mounted by docker-compose.
WORKDIR /app
COPY . .

# Add the /app directory to the PYTHONPATH so Python can find your modules (like 'etl')
# ENV PYTHONPATH=/app
